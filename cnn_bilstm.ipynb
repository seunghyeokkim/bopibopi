{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Bidirectional, LSTM, Attention, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import glorot_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 300\n",
    "num_filters = 32\n",
    "kernel_size = 3\n",
    "num_pooling = 1\n",
    "pooling_size = 2\n",
    "num_dropout = 2\n",
    "spatial_dropout_rate = 0.2\n",
    "dropout_rate = 0.1\n",
    "lstm_units = [64, 32]\n",
    "num_attention = 1\n",
    "num_dense_layers = 2\n",
    "activation_functions = ['relu', 'tanh', 'softmax']\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "learning_decay = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Layer\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, embeddings_initializer=glorot_normal(), input_length=max_sequence_length, trainable=False)) \n",
    "\n",
    "# 1D Convolutional Layer\n",
    "model.add(Conv1D(filters=num_filters, kernel_size=kernel_size, activation=activation_functions[0]))\n",
    "\n",
    "# Max Pooling Layer\n",
    "model.add(MaxPooling1D(pool_size=pooling_size))\n",
    "\n",
    "# Spatial Dropout\n",
    "model.add(tf.keras.layers.SpatialDropout1D(spatial_dropout_rate))\n",
    "\n",
    "# Bidirectional LSTM Layers\n",
    "for units in lstm_units:\n",
    "    model.add(Bidirectional(LSTM(units, return_sequences=True)))\n",
    "\n",
    "# Attention Layer\n",
    "model.add(Attention(use_scale=True))\n",
    "\n",
    "# Fully Connected Layers\n",
    "for _ in range(num_dense_layers):\n",
    "    model.add(Dense(units=64, activation=activation_functions[1]))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(num_classes, activation=activation_functions[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "optimizer = Adam(learning_rate=learning_rate, decay=learning_decay)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation (Example, replace with your own data)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "X_test = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abc",
   "language": "python",
   "name": "hyeokmin"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
